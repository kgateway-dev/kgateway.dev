---
title: AI for LLM consumption
weight: 30
---

With agentgateway, you can route directly to LLM cloud providers, such as OpenAI.

For more information, see the AI Gateway section of the docs.

{{< cards >}}
  {{< card link="../../ai/about" title="About AI Gateway" >}}
  {{< card link="../../ai/setup" title="Set up AI Gateway" >}}
  {{< card link="../../ai/cloud-providers" title="LLM cloud providers" >}}
  {{< card link="../../ai/ollama" title="Ollama for local LLMs" >}}
  {{< card link="../../ai/auth" title="Authenticate LLM providers" >}}
  {{< card link="../../ai/functions" title="Function calling" >}}
  {{< card link="../../integrations/inference-extension" title="Inference Extension for local LLMs" icon="bookmark" >}}
{{< /cards >}}
